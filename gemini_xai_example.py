#!/usr/bin/env python3
"""
Pandora AIOS - Gemini Script with xAI Integration Example
---------------------------------------------------------
Demonstrates how to use the Gemini content script with xAI API

This example shows:
1. Loading the complete Gemini script content
2. Using xAI API to query it
3. Getting intelligent responses about Pandora AIOS
4. Combining xAI with local Pandora knowledge

Usage:
    export XAI_API_KEY="your-api-key"
    python3 gemini_xai_example.py

Author: Pandora AIOS Team
Date: 2025-11-14
"""

import os
import sys
from pathlib import Path

try:
    from xai_api_integration import XAIClient, XAIConfig, PandoraXAIIntegration
except ImportError:
    print("ERROR: xai_api_integration.py not found")
    print("Make sure you're in the Pandora directory")
    sys.exit(1)


def load_gemini_script() -> str:
    """Load the complete Gemini script content"""
    gemini_file = Path(__file__).parent / "gemini_script_content.md"
    
    if not gemini_file.exists():
        print(f"ERROR: {gemini_file} not found")
        sys.exit(1)
    
    with open(gemini_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    return content


def main():
    """Main example function"""
    print("=" * 80)
    print("Pandora AIOS - Gemini Script with xAI Integration")
    print("=" * 80)
    print()
    
    # Check xAI configuration
    config = XAIConfig()
    if not config.is_valid():
        print("‚ö†Ô∏è  xAI API not configured!")
        print()
        print("To use this example:")
        print("1. Get API key from: https://x.ai/api")
        print("2. Set environment variable:")
        print("   export XAI_API_KEY='your-api-key'")
        print("3. Install dependencies:")
        print("   pip install httpx")
        print()
        print("The system will work offline, but xAI provides enhanced responses.")
        print()
        use_xai = False
    else:
        print("‚úÖ xAI API configured")
        print(f"   Model: {config.model}")
        print(f"   Base URL: {config.base_url}")
        print()
        use_xai = True
    
    # Load Gemini script
    print("üìñ Loading Gemini script content...")
    gemini_content = load_gemini_script()
    content_size = len(gemini_content)
    print(f"   ‚úÖ Loaded {content_size:,} characters")
    print()
    
    # Create system prompt from Gemini content
    system_prompt = f"""You are Pandora AIOS, an ethically-driven AI system.

Below is the COMPLETE documentation for Pandora AIOS. Use this information to answer questions accurately:

{gemini_content}

Provide helpful, accurate, and ethical responses based on the documentation above."""
    
    # Initialize xAI client
    if use_xai:
        client = XAIClient(config)
        print("‚úÖ xAI client initialized")
    else:
        client = None
        print("‚ö†Ô∏è  Running in offline mode (no xAI)")
    print()
    
    # Example queries
    queries = [
        "What is Pandora AIOS and what are its core principles?",
        "How does the quantum overlay system work, specifically the Alpha overlay?",
        "What role does Nikola Tesla's philosophy play in Pandora's design?",
        "How can I use the xAI API integration with Pandora?"
    ]
    
    print("=" * 80)
    print("Example Queries with xAI + Gemini Script")
    print("=" * 80)
    print()
    
    for i, query in enumerate(queries, 1):
        print(f"\n{'‚îÄ' * 80}")
        print(f"Query {i}/{len(queries)}: {query}")
        print('‚îÄ' * 80)
        print()
        
        if use_xai and client:
            try:
                # Query xAI with Gemini script as context
                response = client.chat(query, system_prompt=system_prompt)
                print(response)
            except Exception as e:
                print(f"ERROR: {e}")
                print("Falling back to offline mode...")
                print("[Offline response would be generated by local LLM]")
        else:
            print("[Offline Mode]")
            print("In offline mode, the local LLM (GPT4All, Llama, etc.) would")
            print("use the Pandora knowledge base to answer this question.")
        
        print()
    
    # Show usage statistics
    if use_xai and client:
        print("\n" + "=" * 80)
        print("xAI API Usage Statistics")
        print("=" * 80)
        usage = client.get_usage()
        print(f"Total Requests: {usage['total_requests']}")
        print(f"Total Tokens: {usage['total_tokens']}")
        print(f"Total Cost: ${usage['total_cost']:.4f}")
        print()
        
        # Cleanup
        client.close()
    
    # Demonstrate Pandora integration
    print("\n" + "=" * 80)
    print("Advanced: Pandora-xAI Integration")
    print("=" * 80)
    print()
    
    if use_xai:
        print("With PandoraXAIIntegration, you get:")
        print("  ‚Ä¢ xAI Grok responses")
        print("  ‚Ä¢ + Pandora Knowledge Base context")
        print("  ‚Ä¢ + Scientific research papers")
        print("  ‚Ä¢ + All system integrations")
        print()
        print("Example:")
        print("  from xai_api_integration import PandoraXAIIntegration")
        print("  pandora = PandoraXAIIntegration()")
        print("  result = pandora.enhanced_query('quantum computing')")
        print("  # Returns: xAI response + Pandora KB + research papers")
    else:
        print("Configure xAI API to unlock enhanced integration.")
    print()
    
    print("=" * 80)
    print("‚úÖ Example Complete")
    print("=" * 80)
    print()
    print("Next Steps:")
    print("  1. Configure xAI API key for cloud enhancement")
    print("  2. Launch full Pandora: bash LAUNCH_PANDORA.sh")
    print("  3. Use /chat command to interact with the system")
    print("  4. Query research database: /research quantum computing")
    print("  5. Try quantum overlays: /quantum activate alpha")
    print()


if __name__ == "__main__":
    main()
